#  MNN 阿里
MNN 是一个轻量级的深度学习端侧推理引擎，核心解决深度神经网络模型在端侧推理运行问题，涵盖深度神经网络模型的优化、转换和推理。
目前，MNN已经在手淘、手猫、优酷、聚划算、UC、飞猪、千牛等 20 多个 App 中使用，
覆盖直播、短视频、搜索推荐、商品图像搜索、互动营销、权益发放、安全风控等场景，每天稳定运行上亿次。
此外，菜鸟自提柜等 IoT 设备中也有应用。在 2018 年双十一购物节中，MNN 在天猫晚会笑脸红包、扫一扫、明星猜拳大战等场景中使用。

[MNN-APPLICATIONS ](https://github.com/xindongzhang/MNN-APPLICATIONS)


[主仓库](https://github.com/Ewenwan/MNN)

[作者|MNN团队
出品|阿里巴巴新零售淘系技术部](https://www.zhihu.com/search?q=mnn&type=content&range=3m)


MNN 作为阿里巴巴开源的端侧推理引擎，已经支撑了两届淘宝双十一。我们以轻量级的推理引擎和配套工具，支持 Caffe、TensorFlow、PyTorch 训练框架和端侧 CPU、GPU、NPU 上的高效推理。

手机淘宝中有许多对实时性和精度要求都比较高业务，例如视频流检测、拍立淘等等。在算力有限的情况下，性能和精度往往不可兼得 —— 要么接受更慢的响应速度，保障精度，例如放弃视频流，只支持图片；要么舍弃一部分精度，用更小的模型换取更快的速度。

HiAI 是华为端侧 AI 能力开放平台，通过 HiAI Foundation 芯片能力开放，可以借助异构调度和 NPU 加速， 获得更佳的性能和功耗，有了这样性能和功耗同时得以提升的方案， MNN 就可以在配备了 NPU 的设备上启用那个名场面 —— 我全都要！


那么，究竟要怎么做呢？毕竟NPU是完全不同于CPU和GPU的计算设备。在这里，就需要简单回顾一下 MNN 对计算设备的抽象了。

计算设备在 MNN 中，被抽象为 Backend ，即后端；每一种后端都有三种职责：计算资源的分配、计算任务的调度、数据拷贝（含必要的格式转换）。 MNN 在实现对华为 NPU 支持的时候，就依赖了这种抽象设计。

